\documentclass{article} % For LaTeX2e
\usepackage{iclr2018_conference,times}
\usepackage{hyperref}
\usepackage{url}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{comment}
\usepackage{float}
\usepackage{import}
\usepackage{multirow}
\usepackage{subfigure}
\usepackage{tikz}
\usetikzlibrary{positioning}
\usepackage[inline]{enumitem}
\usepackage{amsthm}
\graphicspath{ {images/} }
\usepackage{soul}

%%%%%%%%% Macros %%%%%%%%%%%%%%%%%%
\newtheorem{defn}{Definition}
\newif\ifblind
\def\goldenr{1.618}
\newcommand*\textfrac[2]{
      \frac{\text{#1}}{\text{#2}}
  }
\newcommand{\TODO}[1]{TODO:{#1}}
\newcommand{\etal}{et~al.}
\def\state{s}
\def\statet{\state_t}
\def\statetp{\state_{t-1}}
\def\statetn{\state_{t+1}}
\def\obs{o}
\def\obst{\obs_t}
\def\act{a}
\def\actt{\act_t}
\def\acttp{\act_{t-1}}
\def\acttn{\act_{t+1}}
\def\Obs{\mathcal{O}}
\def\ObsFunc{C}
\def\ObsFuncFull{\ObsFunc(\statet, \actt) \rightarrow \obst}
\def\ObsFuncInv{\ObsFunc^{-1}}
\def\ObsFuncInvFull{\ObsFuncInv(\obst, \statetp, \actt) \rightarrow \statet}
\def\State{\mathcal{S}}
\def\Action{\mathcal{A}}
\def\Trans{T}
\def\TransFull{\Trans(\statet, \actt) \rightarrow \statetn}
\def\TransObs{T_c}
\def\Rew{R}
\def\rew{r}
\def\rewt{\rew_t}
\def\rewtp{\rew_{t-1}}
\def\rewtn{\rew_{t+1}}
\def\RewFull{\Rew(\statet, \actt) \rightarrow \rewtn}
\def\TransObsFull{\TransObs(\statet, \obst, \actt, \rewt; \theta_T) \rightarrow \statetn}
\def\Value{V}
\def\pit{\pi_t}
\def\piDef{\pi(\acttn|\statet, \obst, \actt, \rewt; \theta_\pi) \rightarrow \pit(\acttn ; \theta_\pi)}
\def\Valuet{\Value_t}
\def\ValueDef{\Value(\statet, \obst, \actt, \rewt; \theta_\Value) \rightarrow \Valuet(\theta_\Value)}
\def\R{\mathbb{R}}
\def\E{\mathbb{E}}

\title{BLINC: Querying the Internal Belief States of Deep-Reinforcement Learning Methods}

% Authors must not appear in the submitted version. They should be hidden
% as long as the \iclrfinalcopy macro remains commented out below.
% Non-anonymous submissions will be rejected without review.

\author{Shurjo Banerjee*, Vikas Dhiman*, Brent Griffin \& Jason J. Corso \thanks{indicates equal contribution} \\
The Electrical Engineering and Computer Science Deparment\\
The University of Michigan\\
Ann Arbor, MI 48109, USA \\
\texttt{\{shurjo,dhiman,griffb,jjcorso\}@umich.edu} \\
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.

\begin{document}


\maketitle

\begin{abstract}
    Deep reinforcement learning (DRL) algorithms have demonstrated strong progress in learning to reach a goal in challenging three-dimensional environments without requiring any explicit SLAM or path-planning in their navigation. While promising, the limitations and underlying pattern recognitions performed by these networks based approaches are not very well understood. In this work we introduce the BLINC training paradigm - an appendum to standard DRL models that can be used to (a) Fine-tune DRL algorithms and improve their performance (b) Afford new mechanics allowing for the querying of the internal states of these methods (more details as I figure it out). In BLINC, agents are incentivized to blind themselves as often as possible in the course of their navigation so as to more naturally pick up on aspects of long term blinding. We find that BLINC consistently improves rewards scores by 5\% across multiple environments as worlds. Our querying mechanics provide bot qualitative and quantiative notions of the underlying belief states of the hidden layers of these agents. 

\end{abstract}

\section{Introduction}
\input{blinc-intro-drl-is-black-box}

\section{Related Work}
\input{blinc-related-work}

\section{Background}
\input{blinc-background}

\section{Approach}
\input{blinc-approach}

\section{Experiments}
\input{blinc-experiments}

\section{Analysis}
\input{blinc-analysis}

\section{Conclusion}
\input{blinc-conclusion}


\subsubsection*{Acknowledgments}

Use unnumbered third level headings for the acknowledgments. All
acknowledgments, including those to funding agencies, go at the end of the paper.

\bibliography{iclr2018_conference}
\bibliography{shared}
\bibliographystyle{iclr2018_conference}

\end{document}
